# Code for expanding Wikitext templates, arguments, parser functions, and
# Lua macros.
#
# Copyright (c) 2020 Tatu Ylonen.  See file LICENSE and https://ylonen.org

import os
import re
import sys
import copy
import html
import base64
import os.path
import traceback
import collections
import html.entities
import lupa
from lupa import LuaRuntime

from .context import WtpContext
from .wikiparserfns import (PARSER_FUNCTIONS, call_parser_function, tag_fn)
from .wikihtml import ALLOWED_HTML_TAGS
from wiktextract import wikitext
from wiktextract.wikitext import WikiNode, NodeKind
from wiktextract import languages

# List of search paths for Lua libraries.
builtin_lua_search_paths = [
    # [path, ignore_modules]
    ["lua", ["string", "debug"]],
    ["lua/mediawiki-extensions-Scribunto/includes/engines/LuaCommon/lualib",
     []],
]

# Set of HTML tags that need an explicit end tag.
PAIRED_HTML_TAGS = set(k for k, v in ALLOWED_HTML_TAGS.items()
                       if not v.get("no-end-tag"))

# Set of known language codes.
KNOWN_LANGUAGE_TAGS = set(x["code"] for x in languages.all_languages
                          if x.get("code") and x.get("name"))

# Mapping from language code code to language name.
LANGUAGE_CODE_TO_NAME = { x["code"]: x["name"]
                          for x in languages.all_languages
                          if x.get("code") and x.get("name") }


def canonicalize_template_name(name):
    """Canonicalizes a template name by making its first character uppercase
    and replacing underscores by spaces and sequences of whitespace by a single
    whitespace."""
    assert isinstance(name, str)
    name = re.sub(r"_", " ", name)
    name = re.sub(r"\s+", " ", name)
    name = re.sub(r"\(", "%28", name)
    name = re.sub(r"\)", "%29", name)
    name = re.sub(r"&", "%26", name)
    name = re.sub(r"\+", "%2B", name)
    name = name.strip()
    if name[:9].lower() == "template:":
        name = name[9:]
    if name:
        name = name[0].upper() + name[1:]
    return name


def canonicalize_parserfn_name(name):
    """Canonicalizes a parser function name by making its first character
    uppercase and replacing underscores by spaces and sequences of
    whitespace by a single whitespace."""
    assert isinstance(name, str)
    name = re.sub(r"_", " ", name)
    name = re.sub(r"\s+", " ", name)
    name = name.strip()
    if name not in PARSER_FUNCTIONS:
        name = name.lower()  # Parser function names are case-insensitive
    return name


def template_to_body(title, text):
    """Extracts the portion to be transcluded from a template body.  This
    returns an str."""
    assert isinstance(title, str)
    assert isinstance(text, str)
    # Preprocess the template, handling, e.g., <nowiki> ... </nowiki> and
    # HTML comments
    text = wikitext.preprocess_text(text)
    # Remove all text inside <noinclude> ... </noinclude>
    text = re.sub(r"(?is)<\s*noinclude\s*>.*?<\s*/\s*noinclude\s*>",
                  "", text)
    text = re.sub(r"(?is)<\s*noinclude\s*/\s*>", "", text)
    # <onlyinclude> tags, if present, include the only text that will be
    # transcluded.  All other text is ignored.
    onlys = list(re.finditer(r"(?is)<\s*onlyinclude\s*>(.*?)"
                             r"<\s*/\s*onlyinclude\s*>|"
                             r"<\s*onlyinclude\s*/\s*>",
                             text))
    if onlys:
        text = "".join(m.group(1) or "" for m in onlys)
    # Remove <includeonly>.  They mark text that is not visible on the page
    # itself but is included in transclusion.  Also text outside these tags
    # is included in transclusion.
    text = re.sub(r"(?is)<\s*(/\s*)?includeonly\s*(/\s*)?>", "", text)
    # Sanity checks for certain unbalanced tags.  However, it appears some
    # templates intentionally produce these and intend them to be displayed.
    # Thus don't warn, and we may even need to arrange for them to be properly
    # parsed as text.
    if False:
       m = re.search(r"(?is)<\s*(/\s*)?noinclude\s*(/\s*)?>", text)
       if m:
           print("{}: unbalanced {}".format(title, m.group(0)))
       m = re.search(r"(?is)<\s*(/\s*)?onlyinclude\s*(/\s*)?>", text)
       if m:
           print("{}: unbalanced {}".format(title, m.group(0)))
    return text


def analyze_template(name, body):
    """Analyzes a template body and returns a set of the canonicalized
    names of all other templates it calls and a boolean that is True
    if it should be pre-expanded before final parsing and False if it
    need not be pre-expanded.  The pre-expanded flag is determined
    based on that body only; the caller should propagate it to
    templates that include the given template.  This does not work for
    template and template function calls where the name is generated by
    other expansions."""
    assert isinstance(body, str)
    included_templates = set()
    pre_expand = False

    # Determine if the template starts with a list item
    contains_list = re.match(r"(?s)^[#*;:]", body) is not None

    # Remove paired tables
    prev = body
    while True:
        unpaired_text = re.sub(
            r"(?s)(^|\n)\{\|([^\n]|\n+[^{|]|\n+\|[^}]|\n+\{[^|])*?\n+\|\}",
            r"", prev)
        if unpaired_text == prev:
            break
        prev = unpaired_text
    #print("unpaired_text {!r}".format(unpaired_text))

    # Determine if the template contains an unpaired table
    contains_unpaired_table = re.search(r"(?s)(^|\n)(\{\||\|\})",
                                        unpaired_text) is not None

    # Determine if the template contains table element tokens outside
    # paired table start/end.  We only try to look for these outside templates,
    # as it is common to write each template argument on its own line starting
    # with a "|".
    outside = unpaired_text
    while True:
        #print("=== OUTSIDE ITER")
        prev = outside
        while True:
            newt = re.sub(r"(?s)\{\{\{([^{}]|\}[^}]|\}\}[^}])*?\}\}\}",
                          "", prev)
            if newt == prev:
                break
            prev = newt
        #print("After arg elim: {!r}".format(newt))
        newt = re.sub(r"(?s)\{\{([^{}]|\}[^}])*?\}\}", "", newt)
        #print("After templ elim: {!r}".format(newt))
        if newt == outside:
            break
        outside = newt
    # For now, we'll ignore !! and ||
    m = re.search(r"(?s)(^|\n)(\|\+|\|-|\||\!)", outside)
    contains_table_element = m is not None
    # if contains_table_element:
    #     print("contains_table_element {!r} at {}"
    #           "".format(m.group(0), m.start()))
    #     print("... {!r} ...".format(outside[m.start() - 10:m.end() + 10]))
    #     print(repr(outside))

    # Check for unpaired HTML tags
    tag_cnts = collections.defaultdict(int)
    for m in re.finditer(r"(?si)<\s*(/\s*)?({})\b\s*[^>]*(/\s*)?>"
                         r"".format("|".join(PAIRED_HTML_TAGS)), outside):
        start_slash = m.group(1)
        tagname = m.group(2)
        end_slash = m.group(3)
        if start_slash:
            tag_cnts[tagname] -= 1
        elif not end_slash:
            tag_cnts[tagname] += 1
    contains_unbalanced_html = any(v != 0 for v in tag_cnts.values())
    # if contains_unbalanced_html:
    #     print(name, "UNBALANCED HTML")
    #     for k, v in tag_cnts.items():
    #         if v != 0:
    #             print("  {} {}".format(v, k))

    # Determine whether this template should be pre-expanded
    pre_expand = (contains_list or contains_unpaired_table or
                  contains_table_element or contains_unbalanced_html)

    # if pre_expand:
    #     print(name,
    #           {"list": contains_list,
    #            "unpaired_table": contains_unpaired_table,
    #            "table_element": contains_table_element,
    #            "unbalanced_html": contains_unbalanced_html,
    #            "pre_expand": pre_expand,
    #     })

    # Determine which other templates are called from unpaired text.
    # None of the flags we currently gather propagate outside a paired
    # table start/end.
    for m in re.finditer(r"(?s)(^|[^{])(\{\{)?\{\{([^{]*?)(\||\}\})",
                         unpaired_text):
        name = m.group(3)
        name = re.sub(r"(?si)<\s*nowiki\s*/\s*>", "", name)
        name = canonicalize_template_name(name)
        if not name:
            continue
        included_templates.add(name)

    return included_templates, pre_expand


def lua_loader(ctx, modname):
    """This function is called from the Lua sandbox to load a Lua module.
    This will load it from either the user-defined modules on special
    pages or from a built-in module in the file system.  This returns None
    if the module could not be loaded."""
    assert isinstance(ctx, WtpContext)
    assert isinstance(modname, str)
    # print("Loading", modname)
    modname = modname.strip()
    if modname.startswith("Module:"):
        modname = modname[7:]
    modname1 = re.sub(" ", "_", modname)
    if modname1 in ctx.modules:
        return ctx.modules[modname1]
    path = modname
    path = re.sub(r":", "/", path)
    path = re.sub(r" ", "_", path)
    # path = re.sub(r"\.", "/", path)
    path = re.sub(r"//+", "/", path)
    path = re.sub(r"\.\.", ".", path)
    if path.startswith("/"):
        path = path[1:]
    path += ".lua"
    for prefix, exceptions in builtin_lua_search_paths:
        if modname in exceptions:
            continue
        p = prefix + "/" + path
        if os.path.isfile(p):
            with open(p, "r") as f:
                data = f.read()
            return data
    print("{}: ERROR: Lua module not found: NOT FOUND: {} at {}"
          .format(ctx.title, modname, ctx.stack))
    return None


def mw_text_decode(text, decodeNamedEntities=False):
    """Implements the mw.text.decode function for Lua code."""
    if decodeNamedEntities:
        return html.unescape(text)

    # Otherwise decode only selected entities
    parts = []
    pos = 0
    for m in re.finditer(r"&(lt|gt|amp|quot|nbsp);", text):
        if pos < m.start():
            parts.append(text[pos:m.start()])
        pos = m.end()
        tag = m.group(1)
        if tag == "lt":
            parts.append("<")
        elif tag == "gt":
            parts.append(">")
        elif tag == "amp":
            parts.append("&")
        elif tag == "quot":
            parts.append('"')
        elif tag == "nbsp":
            parts.append("\xa0")
        else:
            assert False
    parts.append(text[pos:])
    return "".join(parts)

def mw_text_encode(text, charset='<>&\xa0"'):
    """Implements the mw.text.encode function for Lua code."""
    parts = []
    for ch in str(text):
        if ch in charset:
            chn = ord(ch)
            if chn in html.entities.codepoint2name:
                parts.append("&" + html.entities.codepoint2name.get(chn) + ";")
            else:
                parts.append(ch)
        else:
            parts.append(ch)
    return "".join(parts)


def get_page_info(ctx, title):
    """Retrieves information about a page identified by its table (with
    namespace prefix.  This returns a lua table with fields "id", "exists",
    and "redirectTo".  This is used for retrieving information about page
    titles."""
    assert isinstance(title, str)

    # XXX actually look at information collected in phase 1 to determine
    page_id = 0  # XXX collect required info in phase 1
    page_exists = False  # XXX collect required info in Phase 1
    redirect_to = ctx.redirects.get(title, None)

    # whether the page exists and what its id might be
    dt = {
        "id": page_id,
        "exists": page_exists,
        "redirectTo": redirect_to,
    }
    return ctx.lua.table_from(dt)


def get_page_content(ctx, title):
    """Retrieves the full content of the page identified by the title.
    Currently this will only return content for the current page.
    This returns None if the page is other than the current page, and
    False if the page does not exist (currently not implemented)."""
    assert isinstance(title, str)
    if title == ctx.title:
        return ctx.fullpage
    if title in ctx.page_contents:
        return ctx.page_contents[title]
    # XXX pages commonly try to access content from other pages, and that
    # really should be supported somehow
    # print("{}: attempted to access page content for {} which is not available"
    #       .format(ctx.title, title))
    # sys.stdout.flush()
    return ""


def fetch_language_name(code):
    """This function is called from Lua code as part of the mw.language
    inmplementation.  This maps a language code to its name."""
    if code in LANGUAGE_CODE_TO_NAME:
        return LANGUAGE_CODE_TO_NAME[code]
    return None


def fetch_language_names(ctx, include):
    """This function is called from Lua code as part of the mw.language
    implementation.  This returns a list of known language names."""
    include = str(include)
    if include == "all":
        ret = LANGUAGE_CODE_TO_NAME
    else:
        ret = {"en": "English"}
    return ctx.lua.table_from(dt)
